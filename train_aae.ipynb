{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "occupational-commonwealth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recons_loss</th>\n",
       "      <th>G_loss</th>\n",
       "      <th>D_loss</th>\n",
       "      <th>d_lr</th>\n",
       "      <th>g_lr</th>\n",
       "      <th>batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.105319</td>\n",
       "      <td>0.783320</td>\n",
       "      <td>0.686990</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.105099</td>\n",
       "      <td>0.783045</td>\n",
       "      <td>0.687215</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.104804</td>\n",
       "      <td>0.782895</td>\n",
       "      <td>0.687283</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.104422</td>\n",
       "      <td>0.782868</td>\n",
       "      <td>0.687289</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.104031</td>\n",
       "      <td>0.782825</td>\n",
       "      <td>0.687157</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.103937</td>\n",
       "      <td>0.782636</td>\n",
       "      <td>0.687256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.103852</td>\n",
       "      <td>0.782755</td>\n",
       "      <td>0.687221</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.103509</td>\n",
       "      <td>0.782722</td>\n",
       "      <td>0.687226</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.103390</td>\n",
       "      <td>0.783081</td>\n",
       "      <td>0.687037</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.103297</td>\n",
       "      <td>0.782766</td>\n",
       "      <td>0.687312</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.103125</td>\n",
       "      <td>0.782995</td>\n",
       "      <td>0.687006</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.102955</td>\n",
       "      <td>0.783032</td>\n",
       "      <td>0.687142</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.102801</td>\n",
       "      <td>0.783120</td>\n",
       "      <td>0.687100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.102703</td>\n",
       "      <td>0.782663</td>\n",
       "      <td>0.687318</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.102288</td>\n",
       "      <td>0.782841</td>\n",
       "      <td>0.687152</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.102207</td>\n",
       "      <td>0.783051</td>\n",
       "      <td>0.687009</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.102117</td>\n",
       "      <td>0.782916</td>\n",
       "      <td>0.687174</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.102001</td>\n",
       "      <td>0.783046</td>\n",
       "      <td>0.687124</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.101786</td>\n",
       "      <td>0.783143</td>\n",
       "      <td>0.687018</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.101893</td>\n",
       "      <td>0.783074</td>\n",
       "      <td>0.687188</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.101388</td>\n",
       "      <td>0.783089</td>\n",
       "      <td>0.687015</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.101540</td>\n",
       "      <td>0.783171</td>\n",
       "      <td>0.687096</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.101308</td>\n",
       "      <td>0.783141</td>\n",
       "      <td>0.687180</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.101043</td>\n",
       "      <td>0.782977</td>\n",
       "      <td>0.687123</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.100794</td>\n",
       "      <td>0.782825</td>\n",
       "      <td>0.687319</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.100558</td>\n",
       "      <td>0.782701</td>\n",
       "      <td>0.687235</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.100586</td>\n",
       "      <td>0.783151</td>\n",
       "      <td>0.686948</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[32]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    recons_loss    G_loss    D_loss   d_lr   g_lr batch_size\n",
       "0      0.105319  0.783320  0.686990  0.001  0.001       [32]\n",
       "1      0.105099  0.783045  0.687215  0.001  0.001       [32]\n",
       "2      0.104804  0.782895  0.687283  0.001  0.001       [32]\n",
       "3      0.104422  0.782868  0.687289  0.001  0.001       [32]\n",
       "4      0.104031  0.782825  0.687157  0.001  0.001       [32]\n",
       "5      0.103937  0.782636  0.687256  0.001  0.001       [32]\n",
       "6      0.103852  0.782755  0.687221  0.001  0.001       [32]\n",
       "7      0.103509  0.782722  0.687226  0.001  0.001       [32]\n",
       "8      0.103390  0.783081  0.687037  0.001  0.001       [32]\n",
       "9      0.103297  0.782766  0.687312  0.001  0.001       [32]\n",
       "10     0.103125  0.782995  0.687006  0.001  0.001       [32]\n",
       "11     0.102955  0.783032  0.687142  0.001  0.001       [32]\n",
       "12     0.102801  0.783120  0.687100  0.001  0.001       [32]\n",
       "13     0.102703  0.782663  0.687318  0.001  0.001       [32]\n",
       "14     0.102288  0.782841  0.687152  0.001  0.001       [32]\n",
       "15     0.102207  0.783051  0.687009  0.001  0.001       [32]\n",
       "16     0.102117  0.782916  0.687174  0.001  0.001       [32]\n",
       "17     0.102001  0.783046  0.687124  0.001  0.001       [32]\n",
       "18     0.101786  0.783143  0.687018  0.001  0.001       [32]\n",
       "19     0.101893  0.783074  0.687188  0.001  0.001       [32]\n",
       "20     0.101388  0.783089  0.687015  0.001  0.001       [32]\n",
       "21     0.101540  0.783171  0.687096  0.001  0.001       [32]\n",
       "22     0.101308  0.783141  0.687180  0.001  0.001       [32]\n",
       "23     0.101043  0.782977  0.687123  0.001  0.001       [32]\n",
       "24     0.100794  0.782825  0.687319  0.001  0.001       [32]\n",
       "25     0.100558  0.782701  0.687235  0.001  0.001       [32]\n",
       "26     0.100586  0.783151  0.686948  0.001  0.001       [32]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!/scratch/sagar/Projects/radio_map_deep_prior/venv/bin/python3.6\n",
    "\n",
    "from collections import OrderedDict, namedtuple\n",
    "from itertools import product\n",
    "import os\n",
    "from tqdm import tqdm, trange\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch\n",
    "from models.aae import AAE\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset import MNISTDataset, MNIST_mean, MNIST_std\n",
    "from utils.plot_utils import show_latent\n",
    "from utils.run_manager import RunBuilder\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    devices = ['cuda']\n",
    "else:\n",
    "    devices = ['cpu']\n",
    "print('starting')\n",
    "\n",
    "params = OrderedDict(\n",
    "    d_lr = [0.001],\n",
    "    ae_lr = [0.001],\n",
    "    batch_size = [32],\n",
    "    device = devices,\n",
    "    shuffle = [True],\n",
    "    num_workers = [5],\n",
    "    beta = [10],\n",
    "    z_dim = [9], \n",
    "    manual_seed = [1265],\n",
    "    loss_func = [nn.MSELoss]\n",
    ")\n",
    "\n",
    "\n",
    "train_set = MNISTDataset(path='data/MNIST/processed', normalize=True)\n",
    "val_set = MNISTDataset(path='data/MNIST/processed', train=False, normalize=True)\n",
    "\n",
    "real_label = 0.9\n",
    "fake_label = 0\n",
    "\n",
    "criterion_adv = nn.BCELoss()\n",
    "alpha = 0.0001\n",
    "Tc = 0\n",
    "Td = 0\n",
    "T_train = 100\n",
    "\n",
    "count=0\n",
    "run_data = []\n",
    "\n",
    "for run in RunBuilder.get_runs(params):\n",
    "    device = torch.device(run.device)\n",
    "#     aae = AAE(latent_dim=run.z_dim).to(run.device)\n",
    "    try:\n",
    "        aae = torch.load('trained_models/mnist_aae_jun7_z_9.model')\n",
    "        print('loaded successfully')\n",
    "    except:\n",
    "        aae = AAE(latent_dim=run.z_dim).to(run.device)\n",
    "\n",
    "    \n",
    "    loader = torch.utils.data.DataLoader(train_set, \n",
    "                                         batch_size=run.batch_size, \n",
    "                                         shuffle=run.shuffle, \n",
    "                                         num_workers=run.num_workers\n",
    "                                        )\n",
    "    \n",
    "    val_loader = torch.utils.data.DataLoader(val_set, \n",
    "                                         batch_size=run.batch_size, \n",
    "                                         shuffle=run.shuffle, \n",
    "                                         num_workers=run.num_workers\n",
    "                                        )\n",
    "    \n",
    "    optimizerAE = torch.optim.Adam(aae.autoencoder.parameters(), lr=run.ae_lr)\n",
    "    optimizerDiscriminator = torch.optim.Adam(aae.discriminator.parameters(), lr=run.d_lr)\n",
    "\n",
    "    num_batches = len(train_set)/run.batch_size\n",
    "    criterion_recons = run.loss_func()\n",
    "    \n",
    "    num_val_batches = len(val_set)/run.batch_size\n",
    "    \n",
    "    for epoch in range(27):\n",
    "\n",
    "        total_adv_loss = 0\n",
    " \n",
    "        real_count = 0\n",
    "        fake_count = 0\n",
    "        \n",
    "        total_D_real = 0\n",
    "        total_D_fake = 0\n",
    "        \n",
    "        total_D_loss = 0\n",
    "        total_G_loss = 0\n",
    "        \n",
    "        total_recons_loss = 0\n",
    "        \n",
    "        num_batches = len(train_set)/run.batch_size\n",
    "        i=0\n",
    "        for batch in tqdm(loader):\n",
    "            i+=1\n",
    "\n",
    "            # Get data\n",
    "            image = batch\n",
    "            image = image.to(run.device)\n",
    "            \n",
    "            b_size = image.size(0)\n",
    "            labels_real = torch.full((b_size,1), real_label, device=run.device, dtype=torch.float32)\n",
    "            labels_fake = torch.full((b_size,1), fake_label, device=run.device, dtype=torch.float32)\n",
    "            \n",
    "            sample_real = torch.randn((b_size, run.z_dim), dtype=torch.float32)\n",
    "            sample_real = sample_real.to(run.device)\n",
    "            \n",
    "            # update autoencoder\n",
    "            optimizerAE.zero_grad()\n",
    "            out = aae.autoencoder(image)\n",
    "            loss = criterion_recons(out, image)\n",
    "            loss.backward()\n",
    "            optimizerAE.step()\n",
    "            \n",
    "            total_recons_loss += loss.item()\n",
    "            \n",
    "            \n",
    "            # Update Generator\n",
    "            optimizerAE.zero_grad()\n",
    "\n",
    "            fake = aae.autoencoder.encoder(image)\n",
    "            fake_pred = aae.discriminator(fake)\n",
    "            gen_loss = criterion_adv(fake_pred, labels_real)\n",
    "            gen_loss.backward()\n",
    "            optimizerAE.step()\n",
    "            \n",
    "            # Update Discriminator\n",
    "            optimizerDiscriminator.zero_grad()\n",
    "            \n",
    "            sample_fake = fake.detach().clone()\n",
    "            \n",
    "            real_loss = criterion_adv(aae.discriminator(sample_real), labels_real)\n",
    "            fake_loss = criterion_adv(aae.discriminator(sample_fake), labels_fake)\n",
    "            d_loss = 0.5*(real_loss + fake_loss)\n",
    "            d_loss.backward()\n",
    "            optimizerDiscriminator.step()\n",
    "            \n",
    "            total_D_real += real_loss.item()\n",
    "            total_D_fake += fake_loss.item()\n",
    "        \n",
    "            total_D_loss += d_loss.item()\n",
    "            total_G_loss += gen_loss.item()\n",
    "\n",
    "            \n",
    "        results = OrderedDict()\n",
    "        results['recons_loss'] = total_recons_loss/num_batches\n",
    "        results['G_loss'] = total_G_loss/num_batches\n",
    "        results['D_loss'] = total_D_loss/num_batches\n",
    "        results['d_lr'] = run.d_lr\n",
    "        results['g_lr'] = run.ae_lr\n",
    "        results['batch_size'] = [run.batch_size]\n",
    "        run_data.append(results)\n",
    "        df = pd.DataFrame.from_dict(run_data, orient='columns')\n",
    "        clear_output(wait=True)\n",
    "        display(df)\n",
    "        \n",
    "        torch.save(aae, 'trained_models/mnist_aae_jun7_z_9.model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-convertible",
   "metadata": {},
   "source": [
    "## Train semi-supervised AAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "liked-needle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recons_loss</th>\n",
       "      <th>G_loss</th>\n",
       "      <th>D_loss</th>\n",
       "      <th>d_lr</th>\n",
       "      <th>g_lr</th>\n",
       "      <th>batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.609448</td>\n",
       "      <td>1.419309</td>\n",
       "      <td>0.449500</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.573456</td>\n",
       "      <td>1.443974</td>\n",
       "      <td>0.476211</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.566959</td>\n",
       "      <td>1.498440</td>\n",
       "      <td>0.479951</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.564397</td>\n",
       "      <td>1.591559</td>\n",
       "      <td>0.467816</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.562942</td>\n",
       "      <td>1.685770</td>\n",
       "      <td>0.463018</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.544475</td>\n",
       "      <td>1.136931</td>\n",
       "      <td>0.645106</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.544379</td>\n",
       "      <td>1.159762</td>\n",
       "      <td>0.640798</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.544804</td>\n",
       "      <td>1.148005</td>\n",
       "      <td>0.648952</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.544339</td>\n",
       "      <td>1.182510</td>\n",
       "      <td>0.637769</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.543068</td>\n",
       "      <td>1.169989</td>\n",
       "      <td>0.644037</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[32]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    recons_loss    G_loss    D_loss   d_lr   g_lr batch_size\n",
       "0      0.609448  1.419309  0.449500  0.001  0.001       [32]\n",
       "1      0.573456  1.443974  0.476211  0.001  0.001       [32]\n",
       "2      0.566959  1.498440  0.479951  0.001  0.001       [32]\n",
       "3      0.564397  1.591559  0.467816  0.001  0.001       [32]\n",
       "4      0.562942  1.685770  0.463018  0.001  0.001       [32]\n",
       "..          ...       ...       ...    ...    ...        ...\n",
       "95     0.544475  1.136931  0.645106  0.001  0.001       [32]\n",
       "96     0.544379  1.159762  0.640798  0.001  0.001       [32]\n",
       "97     0.544804  1.148005  0.648952  0.001  0.001       [32]\n",
       "98     0.544339  1.182510  0.637769  0.001  0.001       [32]\n",
       "99     0.543068  1.169989  0.644037  0.001  0.001       [32]\n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!/scratch/sagar/Projects/radio_map_deep_prior/venv/bin/python3.6\n",
    "\n",
    "from collections import OrderedDict, namedtuple\n",
    "from itertools import product\n",
    "import os\n",
    "from tqdm import tqdm, trange\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch\n",
    "from models.aae import AAESemiSupervised\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset import MNISTDataset, MNIST_mean, MNIST_std, MNISTSupervisedDataset, GMM, OneHot\n",
    "from utils.plot_utils import show_latent\n",
    "from utils.run_manager import RunBuilder\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    devices = ['cuda']\n",
    "else:\n",
    "    devices = ['cpu']\n",
    "print('starting')\n",
    "\n",
    "params = OrderedDict(\n",
    "    d_lr = [0.001],\n",
    "    ae_lr = [0.001],\n",
    "    batch_size = [32],\n",
    "    device = devices,\n",
    "    shuffle = [True],\n",
    "    num_workers = [5],\n",
    "    beta = [10],\n",
    "    z_dim = [2], \n",
    "    manual_seed = [1265],\n",
    "    loss_func = [nn.MSELoss]\n",
    ")\n",
    "\n",
    "\n",
    "train_set = MNISTSupervisedDataset(path='data/MNIST/processed', normalize=True)\n",
    "val_set = MNISTSupervisedDataset(path='data/MNIST/processed', train=False, normalize=True)\n",
    "\n",
    "real_label = 0.9\n",
    "fake_label = 0\n",
    "\n",
    "criterion_adv = nn.BCELoss()\n",
    "alpha = 0.0001\n",
    "Tc = 0\n",
    "Td = 0\n",
    "T_train = 100\n",
    "\n",
    "count=0\n",
    "run_data = []\n",
    "\n",
    "\n",
    "for run in RunBuilder.get_runs(params):\n",
    "    device = torch.device(run.device)\n",
    "    aae = AAESemiSupervised().to(run.device)\n",
    "\n",
    "    \n",
    "    loader = torch.utils.data.DataLoader(train_set, \n",
    "                                         batch_size=run.batch_size, \n",
    "                                         shuffle=run.shuffle, \n",
    "                                         num_workers=run.num_workers\n",
    "                                        )\n",
    "    \n",
    "    val_loader = torch.utils.data.DataLoader(val_set, \n",
    "                                         batch_size=run.batch_size, \n",
    "                                         shuffle=run.shuffle, \n",
    "                                         num_workers=run.num_workers\n",
    "                                        )\n",
    "    \n",
    "    gmm_means = GMM(radius=100, num_classes = 10)\n",
    "    one_hot = OneHot(num_classes=10)\n",
    "    \n",
    "    optimizerAE = torch.optim.Adam(aae.autoencoder.parameters(), lr=run.ae_lr)\n",
    "    optimizerDiscriminator = torch.optim.Adam(aae.discriminator.parameters(), lr=run.d_lr)\n",
    "\n",
    "    num_batches = len(train_set)/run.batch_size\n",
    "    criterion_recons = run.loss_func()\n",
    "    \n",
    "    num_val_batches = len(val_set)/run.batch_size\n",
    "    \n",
    "    for epoch in range(100):\n",
    "\n",
    "        total_adv_loss = 0\n",
    " \n",
    "        real_count = 0\n",
    "        fake_count = 0\n",
    "        \n",
    "        total_D_real = 0\n",
    "        total_D_fake = 0\n",
    "        \n",
    "        total_D_loss = 0\n",
    "        total_G_loss = 0\n",
    "        \n",
    "        total_recons_loss = 0\n",
    "        \n",
    "        num_batches = len(train_set)/run.batch_size\n",
    "        i=0\n",
    "        for batch in tqdm(loader):\n",
    "            i+=1\n",
    "\n",
    "            # Get data\n",
    "            image, labels = batch\n",
    "            image = image.to(run.device)\n",
    "            labels = labels.to(run.device)\n",
    "            \n",
    "            b_size = image.size(0)\n",
    "            labels_real = torch.full((b_size,1), real_label, device=run.device, dtype=torch.float32)\n",
    "            labels_fake = torch.full((b_size,1), fake_label, device=run.device, dtype=torch.float32)\n",
    "            \n",
    "            sample_real = gmm_means[labels] + torch.randn((b_size, run.z_dim), dtype=torch.float32)\n",
    "            sample_real = torch.cat((sample_real, one_hot[labels]), dim=1)\n",
    "            sample_real = sample_real.to(run.device)\n",
    "            \n",
    "            # update autoencoder\n",
    "            optimizerAE.zero_grad()\n",
    "            out = aae.autoencoder(image)\n",
    "            loss = criterion_recons(out, image)\n",
    "            loss.backward()\n",
    "            optimizerAE.step()\n",
    "            \n",
    "            total_recons_loss += loss.item()\n",
    "            \n",
    "            \n",
    "            # Update Generator\n",
    "            optimizerAE.zero_grad()\n",
    "\n",
    "            fake = aae.autoencoder.encoder(image)\n",
    "            fake = torch.cat((fake, one_hot[labels].to(device)), dim=1)\n",
    "            fake_pred = aae.discriminator(fake)\n",
    "            gen_loss = criterion_adv(fake_pred, labels_real)\n",
    "            gen_loss.backward()\n",
    "            optimizerAE.step()\n",
    "            \n",
    "            # Update Discriminator\n",
    "            optimizerDiscriminator.zero_grad()\n",
    "            \n",
    "            sample_fake = fake.detach().clone()\n",
    "            \n",
    "            real_loss = criterion_adv(aae.discriminator(sample_real), labels_real)\n",
    "            fake_loss = criterion_adv(aae.discriminator(sample_fake), labels_fake)\n",
    "            d_loss = 0.5*(real_loss + fake_loss)\n",
    "            d_loss.backward()\n",
    "            optimizerDiscriminator.step()\n",
    "            \n",
    "            total_D_real += real_loss.item()\n",
    "            total_D_fake += fake_loss.item()\n",
    "        \n",
    "            total_D_loss += d_loss.item()\n",
    "            total_G_loss += gen_loss.item()\n",
    "\n",
    "            \n",
    "        results = OrderedDict()\n",
    "        results['recons_loss'] = total_recons_loss/num_batches\n",
    "        results['G_loss'] = total_G_loss/num_batches\n",
    "        results['D_loss'] = total_D_loss/num_batches\n",
    "        results['d_lr'] = run.d_lr\n",
    "        results['g_lr'] = run.ae_lr\n",
    "        results['batch_size'] = [run.batch_size]\n",
    "        run_data.append(results)\n",
    "        df = pd.DataFrame.from_dict(run_data, orient='columns')\n",
    "        clear_output(wait=True)\n",
    "        display(df)\n",
    "        \n",
    "        torch.save(aae, 'trained_models/mnist_aae_semisupervised_r_100_2.model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "threaded-volume",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_means = GMM(radius=7, num_classes = 10)\n",
    "one_hot = OneHot(num_classes=10)\n",
    "\n",
    "labels = torch.tensor([0,1,2,3, 4, 5, 6, 7, 8, 9])\n",
    "sample_real = gmm_means[labels] + torch.randn((10, 2), dtype=torch.float32)\n",
    "sample_real = torch.cat((sample_real, one_hot[labels]), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "earned-reliance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 5.6631e+00,  4.1145e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 2.1631e+00,  6.6574e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [-2.1631e+00,  6.6574e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [-5.6631e+00,  4.1145e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [-7.0000e+00,  8.5725e-16,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [-5.6631e+00, -4.1145e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [-2.1631e+00, -6.6574e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 2.1631e+00, -6.6574e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          1.0000e+00,  0.0000e+00],\n",
       "        [ 5.6631e+00, -4.1145e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  1.0000e+00]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "intelligent-ownership",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import MNISTSupervisedDataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "electric-emission",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMM:\n",
    "    def __init__(self, radius=7, num_classes=10):\n",
    "        self.means = []\n",
    "        angles = [2*np.pi/10*i for i in range(num_classes)]\n",
    "        for theta in angles:\n",
    "            self.means.append([radius*np.cos(theta), radius*np.sin(theta)])\n",
    "        \n",
    "    def __getitem__(self, indices: torch.Tensor):\n",
    "        mapping = map(self.means.__getitem__, indices)\n",
    "        accessed_list = torch.tensor(list(mapping), dtype=torch.float32)\n",
    "        return accessed_list\n",
    "    \n",
    "class OneHot:\n",
    "    def __init__(self, num_classes=10):\n",
    "        self.encoding_vecs = np.eye(num_classes)\n",
    "        \n",
    "    def __getitem__(self, indices: torch.Tensor):\n",
    "        mapping = map(self.encoding_vecs.__getitem__, indices)\n",
    "        accessed_list = torch.tensor(list(mapping), dtype=torch.float32)\n",
    "        return accessed_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "lasting-beijing",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = OneHot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "demographic-harassment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot[torch.tensor([1,3])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "sound-cloud",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(np.eye(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "editorial-favorite",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.eye(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "religious-basis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "italian-interpretation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 4., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.tensor([4,4])\n",
    "torch.cat((b,a[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ceramic-female",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = GMM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "danish-concord",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.0000e+00,  0.0000e+00],\n",
       "        [ 5.6631e+00,  4.1145e+00],\n",
       "        [ 2.1631e+00,  6.6574e+00],\n",
       "        [-2.1631e+00,  6.6574e+00],\n",
       "        [-5.6631e+00,  4.1145e+00],\n",
       "        [-7.0000e+00,  8.5725e-16],\n",
       "        [-5.6631e+00, -4.1145e+00],\n",
       "        [-2.1631e+00, -6.6574e+00],\n",
       "        [ 2.1631e+00, -6.6574e+00],\n",
       "        [ 5.6631e+00, -4.1145e+00]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[torch.tensor([0,1, 2,3, 4, 5, 6, 7, 8, 9])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-chrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "numerous-taylor",
   "metadata": {},
   "outputs": [],
   "source": [
    "a =torch.tensor([1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-stable",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "positive-librarian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(5), tensor(5)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-hawaiian",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "round-stockholm",
   "metadata": {},
   "outputs": [],
   "source": [
    "angles = [2*np.pi/10*i for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "british-punishment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2], 3, [1, 2], 2, 2]\n"
     ]
    }
   ],
   "source": [
    "a_list = [[1,2], 2, 3]\n",
    "\n",
    "indices_to_access = [0, 2, 0, 1, 1]\n",
    "\n",
    "\n",
    "accessed_mapping = map(a_list.__getitem__, indices_to_access)\n",
    "\n",
    "accessed_list = list(accessed_mapping)\n",
    "\n",
    "\n",
    "print(accessed_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "consecutive-process",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "must be real number, not map",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-8b6dbb8b1219>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccessed_mapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: must be real number, not map"
     ]
    }
   ],
   "source": [
    "torch.tensor(accessed_mapping, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "blond-fashion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.283185307179586"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "economic-poultry",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "wireless-planet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.141592653589793"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aboriginal-injury",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function _VariableFunctionsClass.arccos>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arccos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-thanks",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "narrative-fireplace",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/sagar/Projects/flow/ae_flow/dataset.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.dataset = torch.tensor(self.dataset, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "train_set = MNISTSupervisedDataset(path='data/MNIST/processed', normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "indirect-labor",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = train_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "collective-template",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "lucky-adaptation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "meaningful-discount",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "elegant-brain",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "essential-woman",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(train_set, \n",
    "                                         batch_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "stone-infrastructure",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = enumerate(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fewer-domestic",
   "metadata": {},
   "outputs": [],
   "source": [
    "c,b = next(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "tired-placement",
   "metadata": {},
   "outputs": [],
   "source": [
    "r,t = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "historic-madagascar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 2, 8, 6, 9, 4, 0, 9, 1, 1, 2, 4, 3, 2, 7])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-companion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-southeast",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-preference",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-trailer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
