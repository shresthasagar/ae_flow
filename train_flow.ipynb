{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_count</th>\n",
       "      <th>epoch</th>\n",
       "      <th>data_fidelity</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>device</th>\n",
       "      <th>z_dim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.424574</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.418779</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.419978</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.418247</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.417236</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.419768</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.419205</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.417698</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.418449</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.415519</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.417710</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.416881</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.418670</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.413828</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0.417826</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.413827</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.415494</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0.416024</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0.412719</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0.429941</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.414785</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0.412384</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0.412164</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0.418150</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.412182</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.413182</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0.414024</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0.413491</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0.414029</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0.412240</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.412352</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>0.412649</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0.411298</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>0.411661</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>0.430910</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>0.439936</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.420665</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0.416885</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0.410382</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0.410568</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.414588</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0.413112</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0.413559</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    run_count  epoch  data_fidelity  batch_size     lr device  z_dim\n",
       "0           1      0       0.424574          32  0.001   cuda      2\n",
       "1           1      1       0.418779          32  0.001   cuda      2\n",
       "2           1      2       0.419978          32  0.001   cuda      2\n",
       "3           1      3       0.418247          32  0.001   cuda      2\n",
       "4           1      4       0.417236          32  0.001   cuda      2\n",
       "5           1      5       0.419768          32  0.001   cuda      2\n",
       "6           1      6       0.419205          32  0.001   cuda      2\n",
       "7           1      7       0.417698          32  0.001   cuda      2\n",
       "8           1      8       0.418449          32  0.001   cuda      2\n",
       "9           1      9       0.415519          32  0.001   cuda      2\n",
       "10          1     10       0.417710          32  0.001   cuda      2\n",
       "11          1     11       0.416881          32  0.001   cuda      2\n",
       "12          1     12       0.418670          32  0.001   cuda      2\n",
       "13          1     13       0.413828          32  0.001   cuda      2\n",
       "14          1     14       0.417826          32  0.001   cuda      2\n",
       "15          1     15       0.413827          32  0.001   cuda      2\n",
       "16          1     16       0.415494          32  0.001   cuda      2\n",
       "17          1     17       0.416024          32  0.001   cuda      2\n",
       "18          1     18       0.412719          32  0.001   cuda      2\n",
       "19          1     19       0.429941          32  0.001   cuda      2\n",
       "20          1     20       0.414785          32  0.001   cuda      2\n",
       "21          1     21       0.412384          32  0.001   cuda      2\n",
       "22          1     22       0.412164          32  0.001   cuda      2\n",
       "23          1     23       0.418150          32  0.001   cuda      2\n",
       "24          1     24       0.412182          32  0.001   cuda      2\n",
       "25          1     25       0.413182          32  0.001   cuda      2\n",
       "26          1     26       0.414024          32  0.001   cuda      2\n",
       "27          1     27       0.413491          32  0.001   cuda      2\n",
       "28          1     28       0.414029          32  0.001   cuda      2\n",
       "29          1     29       0.412240          32  0.001   cuda      2\n",
       "30          1     30       0.412352          32  0.001   cuda      2\n",
       "31          1     31       0.412649          32  0.001   cuda      2\n",
       "32          1     32       0.411298          32  0.001   cuda      2\n",
       "33          1     33       0.411661          32  0.001   cuda      2\n",
       "34          1     34       0.430910          32  0.001   cuda      2\n",
       "35          1     35       0.439936          32  0.001   cuda      2\n",
       "36          1     36       0.420665          32  0.001   cuda      2\n",
       "37          1     37       0.416885          32  0.001   cuda      2\n",
       "38          1     38       0.410382          32  0.001   cuda      2\n",
       "39          1     39       0.410568          32  0.001   cuda      2\n",
       "40          1     40       0.414588          32  0.001   cuda      2\n",
       "41          1     41       0.413112          32  0.001   cuda      2\n",
       "42          1     42       0.413559          32  0.001   cuda      2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 1620/1875 [00:31<00:04, 51.72it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-162d2e8eb0fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sagar/Projects/flow/ae_flow/models/flow.py\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnvp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sagar/Projects/flow/ae_flow/models/flow.py\u001b[0m in \u001b[0;36mnll\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sagar/Projects/flow/ae_flow/models/flow.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_det\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_det\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sagar/Projects/learn/compressai/venv/lib/python3.6/site-packages/torch/distributions/normal.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;31m# compute the variance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sagar/Projects/learn/compressai/venv/lib/python3.6/site-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36m_validate_sample\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0msupport\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msupport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The value argument must be within the support'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "import os\n",
    "from tqdm import tqdm, trange\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch\n",
    "from models.ae import MNISTAutoencoder\n",
    "from models.flow import Flow\n",
    "from models.generator import MNISTGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset import MNISTDataset, MNIST_mean, MNIST_std, MNISTFlowDataset\n",
    "from utils.run_manager import RunBuilder\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    devices = ['cuda']\n",
    "else:\n",
    "    devices = ['cpu']\n",
    "print('starting')\n",
    "\n",
    "\n",
    "params = OrderedDict(\n",
    "    lr = [0.001],\n",
    "    batch_size = [32],\n",
    "    device = devices,\n",
    "    shuffle = [True],\n",
    "    num_workers = [5],\n",
    "    beta = [10],\n",
    "    z_dim = [2], \n",
    "    manual_seed = [1265],\n",
    "    loss_func = [nn.MSELoss]\n",
    ")\n",
    "\n",
    "\n",
    "ae = torch.load('trained_models/mnist_ae_zdim_2.model')\n",
    "\n",
    "train_set = MNISTFlowDataset(path='data/MNIST/latent')\n",
    "\n",
    "run_count = 0\n",
    "models = []\n",
    "\n",
    "run_data = []\n",
    "\n",
    "data_load_time = 0\n",
    "forward_time = 0\n",
    "for run in RunBuilder.get_runs(params):\n",
    "  \n",
    "    run_count += 1\n",
    "    device = torch.device(run.device)\n",
    "    \n",
    "#     model = Flow()\n",
    "#     model = model.to(device)\n",
    "\n",
    "    loader = torch.utils.data.DataLoader(train_set, \n",
    "                                         batch_size=run.batch_size, \n",
    "                                         shuffle=run.shuffle, \n",
    "                                         num_workers=run.num_workers\n",
    "                                        )\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=run.lr)\n",
    "    num_batches = len(train_set)/run.batch_size\n",
    "    criterion = run.loss_func()\n",
    "    \n",
    "    for epoch in range(100):\n",
    "        total_recons_loss = 0\n",
    "        batch_count = 0\n",
    "        \n",
    "        results = OrderedDict()\n",
    "        results['run_count'] = run_count\n",
    "        results['epoch'] = epoch\n",
    "        results['data_fidelity'] = total_recons_loss/num_batches\n",
    "        results['batch_size'] = run.batch_size\n",
    "        results['lr'] = run.lr\n",
    "        results['device'] = run.device\n",
    "        results['z_dim'] = run.z_dim\n",
    "        \n",
    "#         run_data.append(results)\n",
    "        df2 = pd.DataFrame.from_dict(run_data, orient='columns')\n",
    "        \n",
    "        \n",
    "        for batch in tqdm(loader):\n",
    "            batch_count +=1\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            X = batch\n",
    "            X = X.to(device=run.device)\n",
    "            loss = model.loss(X)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_recons_loss += loss.item()\n",
    "            \n",
    "            \n",
    "        results = OrderedDict()\n",
    "        results['run_count'] = run_count\n",
    "        results['epoch'] = epoch\n",
    "        results['data_fidelity'] = total_recons_loss/num_batches\n",
    "        results['batch_size'] = run.batch_size\n",
    "        results['lr'] = run.lr\n",
    "        results['device'] = run.device\n",
    "        results['z_dim'] = run.z_dim\n",
    "        \n",
    "        run_data.append(results)\n",
    "        df2 = pd.DataFrame.from_dict(run_data, orient='columns')\n",
    "        clear_output(wait=True)\n",
    "        display(df2)\n",
    "            \n",
    "        torch.save(model, 'trained_models/mnist_flow_zdim_2.model'.format(run.lr,run.beta, run.z_dim))\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/sagar/Projects/flow/ae_flow/dataset.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.dataset = torch.tensor(self.dataset, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "ae = torch.load('trained_models/mnist_ae_zdim_2.model')\n",
    "\n",
    "ae.eval()\n",
    "ae = ae.to('cpu')\n",
    "\n",
    "ae_set = MNISTDataset(path='data/MNIST/processed', normalize=True)\n",
    "\n",
    "latent = ae.encoder(ae_set.dataset.unsqueeze(dim=1))\n",
    "lat = latent.detach().clone()\n",
    "\n",
    "torch.save((lat, ae_set.labels), 'data/MNIST/latent/training.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
