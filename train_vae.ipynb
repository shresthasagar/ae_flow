{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adolescent-granny",
   "metadata": {},
   "source": [
    "## Train a VAE on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "portuguese-frank",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_count</th>\n",
       "      <th>epoch</th>\n",
       "      <th>kl_loss</th>\n",
       "      <th>data_fidelity</th>\n",
       "      <th>beta</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>device</th>\n",
       "      <th>z_dim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.064969</td>\n",
       "      <td>0.727232</td>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.177157</td>\n",
       "      <td>0.705482</td>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.293648</td>\n",
       "      <td>0.695282</td>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.410614</td>\n",
       "      <td>0.687599</td>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.528835</td>\n",
       "      <td>0.679812</td>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>11.204729</td>\n",
       "      <td>0.395075</td>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>11.316930</td>\n",
       "      <td>0.394472</td>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>11.438402</td>\n",
       "      <td>0.394490</td>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>11.553703</td>\n",
       "      <td>0.394731</td>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>11.674130</td>\n",
       "      <td>0.393564</td>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    run_count  epoch    kl_loss  data_fidelity  beta  batch_size      lr  \\\n",
       "0           1      0   0.064969       0.727232    10         128  0.0005   \n",
       "1           1      1   0.177157       0.705482    10         128  0.0005   \n",
       "2           1      2   0.293648       0.695282    10         128  0.0005   \n",
       "3           1      3   0.410614       0.687599    10         128  0.0005   \n",
       "4           1      4   0.528835       0.679812    10         128  0.0005   \n",
       "..        ...    ...        ...            ...   ...         ...     ...   \n",
       "95          1     95  11.204729       0.395075    10         128  0.0005   \n",
       "96          1     96  11.316930       0.394472    10         128  0.0005   \n",
       "97          1     97  11.438402       0.394490    10         128  0.0005   \n",
       "98          1     98  11.553703       0.394731    10         128  0.0005   \n",
       "99          1     99  11.674130       0.393564    10         128  0.0005   \n",
       "\n",
       "   device  z_dim  \n",
       "0    cuda      2  \n",
       "1    cuda      2  \n",
       "2    cuda      2  \n",
       "3    cuda      2  \n",
       "4    cuda      2  \n",
       "..    ...    ...  \n",
       "95   cuda      2  \n",
       "96   cuda      2  \n",
       "97   cuda      2  \n",
       "98   cuda      2  \n",
       "99   cuda      2  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAPuklEQVR4nO3df2xd9XnH8c/jazvBjpufxqSQJZRmWxlTk87NOpV2tKgIqLpQaSCyqctUqnQTrLRjHQjUlWnrxLpC1G1VpXREzaYW1K5F5A+2QjOkCGlDOGlGflAWkiUjwXEcnEAgJE7sZ3/4UJng8z3m3nN/JM/7JVn3+jz3+D65+MO5Pt97vl9zdwE4/7U1uwEAjUHYgSAIOxAEYQeCIOxAEO2NfLIFCxb4kiVLGvmUQChbtmw54u69U9VqCruZXSvpm5Iqkv7J3e9LPX7JkiUaGBio5SkBJJjZ/rxa1W/jzawi6VuSrpN0uaRVZnZ5tT8PQH3V8jf7CkkvuPtedx+V9LCkleW0BaBstYT9YkkvTvr+QLbtLcxsjZkNmNnA8PBwDU8HoBZ1Pxvv7uvcvd/d+3t7pzxvAKABagn7QUmLJn1/SbYNQAuqJezPSFpqZpeaWaekmyVtLKctAGWreujN3c+Y2W2SfqKJobf17r6ztM4AlKqmcXZ3f0zSYyX1AqCO+LgsEARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBNHQqaZx7lv/xA8n6yPKxZH3/mi+X2Q5qwJEdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4JgnL0BfuUv1ybrncuPJusL3/Vqsr5g5uu5te72U8l953S8kazfdFv+z5akvo5XkvVv7Pppbm37a29bLewt2m08WR8+OStZ3/iRf0zWo+HIDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBMM5egiX/cH+yvuzqPcn6RRccT9a7K+mx8lmJ+uz2E8l9F3WMpJ+7Lf3cM+10sj6nkn7+lONjM5P1CyqjyfrSH/5Vbm33jV+pqqdzWU1hN7N9ko5LGpN0xt37y2gKQPnKOLJ/zN2PlPBzANQRf7MDQdQadpf0uJltMbM1Uz3AzNaY2YCZDQwPD9f4dACqVWvYr3T3D0i6TtKtZvbRsx/g7uvcvd/d+3t7e2t8OgDVqins7n4wuz0s6RFJK8poCkD5qg67mXWbWc+b9yVdI2lHWY0BKFctZ+P7JD1iZm/+nO+7+7+X0tU5xrvPJOtt5sl6LePoRbra0mPRRePoRY6NdyXrY55/PJldMAbfVdBb0bX0hy5+V7IeTdVhd/e9kt5fYi8A6oihNyAIwg4EQdiBIAg7EARhB4LgEtcS7P/sncl66lJLSZq5KD10VzTdc+pSz6NnupP7VpServmVsfTQWtFlqKnhsaLLX3vb01NoFxnqmV3T/ucbjuxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EATj7A0w87/SSwvvnHlRsr50fno6r+72/HH2wZPpseaOtrFkffex9OxCF3Skp5K+ckH+NNrv7kgvVd3TdjJZP+2VZP3UOL/ek3FkB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgGIhsgO33fylZf989a5P1Z5amx+m7n+/ML1pyV+36m3Rvtbpt6+/l1oqmse4pWA56pGCcfegUU0lPxpEdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4JgnL0FPPe1+o51N9P8jtfza23peePnV9JLXb8ynq4PnexJ1qMpPLKb2XozO2xmOyZtm2dmT5jZ7ux2bn3bBFCr6byN/66ka8/adpekTe6+VNKm7HsALaww7O6+WdLIWZtXStqQ3d8g6YZy2wJQtmpP0PW5+2B2/5CkvrwHmtkaMxsws4Hh4fRcagDqp+az8e7uknLPlLj7Onfvd/f+3t705IUA6qfasA+Z2UJJym4Pl9cSgHqoNuwbJa3O7q+W9Gg57QCol8JxdjN7SNJVkhaY2QFJX5V0n6QfmNktkvZLuqmeTeLcVbH89d972tLXq3dZ+tdzrOBi/cHjjLNPVhh2d1+VU7q65F4A1BEflwWCIOxAEIQdCIKwA0EQdiAILnFFXc2q5C+73FUwzXWR4+MXJOsjQ0wlPRlHdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgnH288Clf39/bu1/v3BHXZ/7sq8/kKx/63cP5tZmtyWWmpZ0WmPJ+rGxrmR9/2fvTNaj4cgOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0Ewzt4Crtj4F8n6L89PL5t11Yfyrxnv/7e7k/v6vy5I1l/+2Klk/Quf+o9k/Vc7j+bWutpmJfd9bTz/3yVJo15J1j+4Ov8zAM9s+NPkvucjjuxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EATj7A3w3r9NX/P9B5/8WbJ+Yceryfqp8Y7cWt+M9L5tt/88WV/etT9Z//UZg8n6vLb8X7Exz1/OWZJOePp69iLtvz+UW7viy2uT++74uy/V9NytqPDIbmbrzeywme2YtO1eMztoZtuyr+vr2yaAWk3nbfx3JV07xfa17r4s+3qs3LYAlK0w7O6+WdJIA3oBUEe1nKC7zcyezd7mz817kJmtMbMBMxsYHk5/xhtA/VQb9m9LukzSMkmDknJnPHT3de7e7+79vb29VT4dgFpVFXZ3H3L3MXcfl/QdSSvKbQtA2aoKu5ktnPTtpyXtyHssgNZQOM5uZg9JukrSAjM7IOmrkq4ys2WSXNI+SZ+vX4vnvj/61E+S9d/seiFZf318RrK+e/Si3Nrs9jeS+75vZv687pL0a52Hk/W+SvUf1Xh5PN3b3tMzk/UjZ9Lrr/d05l+LP/zB15L7no8K/0u5+6opNj9Yh14A1BEflwWCIOxAEIQdCIKwA0EQdiAILnGdpt/e9Ge5tc/90lPJfT/e/VKy3maerB8bTy9NvPeN/E8mzmpPTwU9v5IeguqyZFmnCy5TPTaeX99fMHS2Z/TCZH3kTHey3tU+mlubPSs9TfX5iCM7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgTBOHvmPQ9/LVn/69/YnFt7/4z0ZaKVgnH0l870JOsvjs5P1gdPzs6t/dacvcl9u+10sl40mXNqHF2SXhrL/4zA4bH0v7ti6Z+9oON4sr60J39J59HxeL/6HNmBIAg7EARhB4Ig7EAQhB0IgrADQRB2IIh4g405+uallzbusPwR53GlL/o+UTCme9Lzl1yWpJ5K+trra+bvzK0t7TyU3HdeJT3Onj9SPWFovDNZf3lsVsFPyNfVlr4Wf9TTr+vMtvS/LRqO7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBOPsmZf+L33N+PPvXphbm1N5PblvT1t6nHxR+7FkfXH70WS9M3Hdd9G870VGxtMj7T8fzX9dJOnA6LzcWldb/rzuE/X0OPvRgnnjT4zlfwagveBa+aL5DfbefE+y3ooKj+xmtsjMnjSzXWa208xuz7bPM7MnzGx3dju3/u0CqNZ03safkXSHu18u6UOSbjWzyyXdJWmTuy+VtCn7HkCLKgy7uw+6+9bs/nFJz0m6WNJKSRuyh22QdEOdegRQgnd0gs7MlkhaLulpSX3uPpiVDknqy9lnjZkNmNnA8PBwLb0CqMG0w25msyT9SNIX3f0tV424u0uaclZFd1/n7v3u3t/bm78AIYD6mlbYzaxDE0H/nrv/ONs8ZGYLs/pCSYfr0yKAMhQOvZmZSXpQ0nPu/sCk0kZJqyXdl90+WpcOG2T/5/48Wb/pP/fk1hbPOJLct7sj/f/B2ZX0hM2dlh4/O5mYqbpo6OzFM3OS9a0nliTrm4+8N1kfeSN/KulLeo4l9y1y9FR6KWv3/Ndt5MQFyX3bX0jXz0XTGWf/sKTPSNpuZtuybXdrIuQ/MLNbJO2XdFNdOgRQisKwu/tTUu7sDFeX2w6AeuHjskAQhB0IgrADQRB2IAjCDgTBJa7T9LMDl+TWFneNpHdODwdrVC8n6yfGZyTre0YvzK1tfXVxct8nn74iWd/3J3ck6+et32l2A+XjyA4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQTDOPk27b/xKbu0TbTcm93368Y8k65W29LTGT378/mS9Jivq96PRWjiyA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQjLOX4InxHza7BaAQR3YgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCKIw7Ga2yMyeNLNdZrbTzG7Ptt9rZgfNbFv2dX392wVQrel8qOaMpDvcfauZ9UjaYmZPZLW17v6N+rUHoCzTWZ99UNJgdv+4mT0n6eJ6NwagXO/ob3YzWyJpuaSns023mdmzZrbezObm7LPGzAbMbGB4eLi2bgFUbdphN7NZkn4k6Yvu/qqkb0u6TNIyTRz5p5wozd3XuXu/u/f39vbW3jGAqkwr7GbWoYmgf8/dfyxJ7j7k7mPuPi7pO2LqQqClTedsvEl6UNJz7v7ApO0LJz3s05J2lN8egLJM52z8hyV9RtJ2M9uWbbtb0iozWybJJe2T9Pk69AegJNM5G/+UJJui9Fj57QCoFz5BBwRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCMLcvXFPZjYsaf+kTQskHWlYA+9Mq/bWqn1J9FatMntb7O5Tzv/W0LC/7cnNBty9v2kNJLRqb63al0Rv1WpUb7yNB4Ig7EAQzQ77uiY/f0qr9taqfUn0Vq2G9NbUv9kBNE6zj+wAGoSwA0E0Jexmdq2ZPW9mL5jZXc3oIY+Z7TOz7dky1ANN7mW9mR02sx2Tts0zsyfMbHd2O+Uae03qrSWW8U4sM97U167Zy583/G92M6tI+h9Jn5B0QNIzkla5+66GNpLDzPZJ6nf3pn8Aw8w+Kuk1Sf/s7ldk274uacTd78v+RznX3e9skd7ulfRas5fxzlYrWjh5mXFJN0j6QzXxtUv0dZMa8Lo148i+QtIL7r7X3UclPSxpZRP6aHnuvlnSyFmbV0rakN3foIlflobL6a0luPugu2/N7h+X9OYy40197RJ9NUQzwn6xpBcnfX9ArbXeu0t63My2mNmaZjczhT53H8zuH5LU18xmplC4jHcjnbXMeMu8dtUsf14rTtC93ZXu/gFJ10m6NXu72pJ84m+wVho7ndYy3o0yxTLjv9DM167a5c9r1YywH5S0aNL3l2TbWoK7H8xuD0t6RK23FPXQmyvoZreHm9zPL7TSMt5TLTOuFnjtmrn8eTPC/oykpWZ2qZl1SrpZ0sYm9PE2ZtadnTiRmXVLukattxT1Rkmrs/urJT3axF7eolWW8c5bZlxNfu2avvy5uzf8S9L1mjgjv0fSPc3oIaev90j67+xrZ7N7k/SQJt7WndbEuY1bJM2XtEnSbkk/lTSvhXr7F0nbJT2riWAtbFJvV2riLfqzkrZlX9c3+7VL9NWQ142PywJBcIIOCIKwA0EQdiAIwg4EQdiBIAg7EARhB4L4f1IGnOY4AFzwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import OrderedDict, namedtuple\n",
    "from itertools import product\n",
    "import os\n",
    "from tqdm import tqdm, trange\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch\n",
    "from models.vae import BetaVAE\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset import MNISTDataset, MNIST_mean, MNIST_std\n",
    "\n",
    "\n",
    "class RunBuilder():\n",
    "    @staticmethod\n",
    "    def get_runs(params):\n",
    "\n",
    "        Run = namedtuple('Run', params.keys())\n",
    "\n",
    "        runs = []\n",
    "        for v in product(*params.values()):\n",
    "            runs.append(Run(*v))\n",
    "\n",
    "        return runs\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    devices = ['cuda']\n",
    "else:\n",
    "    devices = ['cpu']\n",
    "print('starting')\n",
    "\n",
    "\n",
    "params = OrderedDict(\n",
    "    lr = [0.0005],\n",
    "    batch_size = [128],\n",
    "    device = devices,\n",
    "    shuffle = [True],\n",
    "    num_workers = [5],\n",
    "    beta = [10],\n",
    "    z_dim = [2], \n",
    "    manual_seed = [1265],\n",
    "    loss_type = ['B']\n",
    ")\n",
    "\n",
    "train_set = MNISTDataset(path='data/MNIST/processed', normalize=True)\n",
    "\n",
    "\n",
    "run_count = 0\n",
    "models = []\n",
    "\n",
    "\n",
    "run_data = []\n",
    "\n",
    "data_load_time = 0\n",
    "forward_time = 0\n",
    "for run in RunBuilder.get_runs(params):\n",
    "#     torch.cuda.set_device(run.device)\n",
    "    \n",
    "    run_count += 1\n",
    "    device = torch.device(run.device)\n",
    "    \n",
    "    model = BetaVAE(\n",
    "                    latent_dim=run.z_dim,\n",
    "                    beta=run.beta,\n",
    "                   loss_type=run.loss_type)\n",
    "    model = model.to(device)\n",
    "    loader = torch.utils.data.DataLoader(train_set, batch_size=run.batch_size, shuffle=run.shuffle, num_workers=run.num_workers)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=run.lr)\n",
    "\n",
    "    num_batches = len(train_set)/run.batch_size\n",
    "    for epoch in range(100):\n",
    "\n",
    "        total_kl_loss = 0\n",
    "        total_recons_loss = 0\n",
    "        batch_count = 0\n",
    "        \n",
    "        results = OrderedDict()\n",
    "        results['run_count'] = run_count\n",
    "        results['epoch'] = epoch\n",
    "        results['kl_loss'] = total_kl_loss/num_batches\n",
    "        results['data_fidelity'] = total_recons_loss/num_batches\n",
    "        results['beta'] = run.beta\n",
    "        results['batch_size'] = run.batch_size\n",
    "        results['lr'] = run.lr\n",
    "        results['device'] = run.device\n",
    "        results['z_dim'] = run.z_dim\n",
    "        \n",
    "#         run_data.append(results)\n",
    "        df2 = pd.DataFrame.from_dict(run_data, orient='columns')\n",
    "        \n",
    "        \n",
    "     \n",
    "        for batch in tqdm(loader):\n",
    "            batch_count +=1\n",
    "#             print('data loading time', time.time() - data_load_time)\n",
    "            optimizer.zero_grad()\n",
    "#             forward_time = time.time()\n",
    "            X= batch\n",
    "            X = X.to(device=run.device)\n",
    "            out = model(X)\n",
    "#             print('forward  time', time.time() - forward_time)\n",
    "            \n",
    "            losses = model.loss_function(*out,\n",
    "                                         M_N = run.batch_size/len(train_set))\n",
    "            losses['loss'].backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "#             print(' backward time', time.time() - forward_time)\n",
    "            total_kl_loss += losses['KLD'].item()\n",
    "            total_recons_loss += losses['Reconstruction_Loss'].item()\n",
    "            \n",
    "#             data_load_time = time.time()\n",
    "            if batch_count % 100 ==0:\n",
    "                clear_output(wait=True)\n",
    "                display(df2)\n",
    "                sample = model.sample(1, device)\n",
    "                sample = sample.to('cpu')\n",
    "                plt.imshow(torch.log(sample+1e-16).detach().squeeze().numpy())\n",
    "                plt.show()\n",
    "            \n",
    "        results = OrderedDict()\n",
    "        results['run_count'] = run_count\n",
    "        results['epoch'] = epoch\n",
    "        results['kl_loss'] = total_kl_loss/num_batches\n",
    "        results['data_fidelity'] = total_recons_loss/num_batches\n",
    "        results['beta'] = run.beta\n",
    "        results['batch_size'] = run.batch_size\n",
    "        results['lr'] = run.lr\n",
    "        results['device'] = run.device\n",
    "        results['z_dim'] = run.z_dim\n",
    "        \n",
    "        run_data.append(results)\n",
    "        df2 = pd.DataFrame.from_dict(run_data, orient='columns')\n",
    "        clear_output(wait=True)\n",
    "        display(df2)\n",
    "        sample = model.sample(1, device)\n",
    "        sample = sample.to('cpu')\n",
    "        plt.imshow(torch.log(sample+1e-16).detach().squeeze().numpy())\n",
    "        plt.show()\n",
    "            \n",
    "#             m.track_loss(G_adv_loss=losses['beta_kl-divergence'], G_mse_loss=losses[''], D_real_loss=total_D_real, D_fake_loss=total_D_fake, D_real_count=real_count, D_fake_count=fake_count)\n",
    "#         print(epoch, \"total_Gloss:\",total_Gloss, \"total_Dloss:\",total_Dloss, \"mse:\",total_mse_loss, \"adv: \", total_adv_loss)           \n",
    "#         m.end_epoch()\n",
    "        torch.save(model, 'trained_models/vae_mnist_zdim_2.model'.format(run.lr,run.beta, run.z_dim))\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-zambia",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
