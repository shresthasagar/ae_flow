{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "italian-congress",
   "metadata": {},
   "source": [
    "## Train AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "spoken-minister",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_count</th>\n",
       "      <th>epoch</th>\n",
       "      <th>data_fidelity</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>device</th>\n",
       "      <th>z_dim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.539689</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.491387</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.469014</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.451386</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.440891</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>0.369499</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>0.369283</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>0.370538</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>0.370574</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>0.368760</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>cuda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    run_count  epoch  data_fidelity  batch_size     lr device  z_dim\n",
       "0           1      0       0.539689          32  0.001   cuda      2\n",
       "1           1      1       0.491387          32  0.001   cuda      2\n",
       "2           1      2       0.469014          32  0.001   cuda      2\n",
       "3           1      3       0.451386          32  0.001   cuda      2\n",
       "4           1      4       0.440891          32  0.001   cuda      2\n",
       "..        ...    ...            ...         ...    ...    ...    ...\n",
       "95          1     95       0.369499          32  0.001   cuda      2\n",
       "96          1     96       0.369283          32  0.001   cuda      2\n",
       "97          1     97       0.370538          32  0.001   cuda      2\n",
       "98          1     98       0.370574          32  0.001   cuda      2\n",
       "99          1     99       0.368760          32  0.001   cuda      2\n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import OrderedDict, namedtuple\n",
    "from itertools import product\n",
    "import os\n",
    "from tqdm import tqdm, trange\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch\n",
    "from models.ae import MNISTAutoencoder\n",
    "from models.generator import MNISTGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset import MNISTDataset, MNIST_mean, MNIST_std\n",
    "\n",
    "class RunBuilder():\n",
    "    @staticmethod\n",
    "    def get_runs(params):\n",
    "\n",
    "        Run = namedtuple('Run', params.keys())\n",
    "\n",
    "        runs = []\n",
    "        for v in product(*params.values()):\n",
    "            runs.append(Run(*v))\n",
    "\n",
    "        return runs\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    devices = ['cuda']\n",
    "else:\n",
    "    devices = ['cpu']\n",
    "print('starting')\n",
    "\n",
    "\n",
    "params = OrderedDict(\n",
    "    lr = [0.001],\n",
    "    batch_size = [32],\n",
    "    device = devices,\n",
    "    shuffle = [True],\n",
    "    num_workers = [5],\n",
    "    beta = [10],\n",
    "    z_dim = [2], \n",
    "    manual_seed = [1265],\n",
    "    loss_func = [nn.MSELoss]\n",
    ")\n",
    "\n",
    "train_set = MNISTDataset(path='data/MNIST/processed', normalize=True)\n",
    "\n",
    "run_count = 0\n",
    "models = []\n",
    "\n",
    "\n",
    "run_data = []\n",
    "\n",
    "data_load_time = 0\n",
    "forward_time = 0\n",
    "for run in RunBuilder.get_runs(params):\n",
    "#     torch.cuda.set_device(run.device)\n",
    "    \n",
    "    run_count += 1\n",
    "    device = torch.device(run.device)\n",
    "    \n",
    "    model = MNISTAutoencoder(latent_dim=run.z_dim)\n",
    "    model = model.to(device)\n",
    "    loader = torch.utils.data.DataLoader(train_set, \n",
    "                                         batch_size=run.batch_size, \n",
    "                                         shuffle=run.shuffle, \n",
    "                                         num_workers=run.num_workers\n",
    "                                        )\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=run.lr)\n",
    "    num_batches = len(train_set)/run.batch_size\n",
    "    criterion = run.loss_func()\n",
    "    \n",
    "    for epoch in range(100):\n",
    "        total_recons_loss = 0\n",
    "        batch_count = 0\n",
    "        \n",
    "        results = OrderedDict()\n",
    "        results['run_count'] = run_count\n",
    "        results['epoch'] = epoch\n",
    "        results['data_fidelity'] = total_recons_loss/num_batches\n",
    "        results['batch_size'] = run.batch_size\n",
    "        results['lr'] = run.lr\n",
    "        results['device'] = run.device\n",
    "        results['z_dim'] = run.z_dim\n",
    "        \n",
    "#         run_data.append(results)\n",
    "        df2 = pd.DataFrame.from_dict(run_data, orient='columns')\n",
    "        \n",
    "        \n",
    "     \n",
    "        for batch in tqdm(loader):\n",
    "            batch_count +=1\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            X = batch\n",
    "            X = X.to(device=run.device)\n",
    "            out = model(X)\n",
    "            \n",
    "            loss = criterion(out, X)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "#             print(' backward time', time.time() - forward_time)\n",
    "            total_recons_loss += loss.item()\n",
    "            \n",
    "            \n",
    "        results = OrderedDict()\n",
    "        results['run_count'] = run_count\n",
    "        results['epoch'] = epoch\n",
    "        results['data_fidelity'] = total_recons_loss/num_batches\n",
    "        results['batch_size'] = run.batch_size\n",
    "        results['lr'] = run.lr\n",
    "        results['device'] = run.device\n",
    "        results['z_dim'] = run.z_dim\n",
    "        \n",
    "        run_data.append(results)\n",
    "        df2 = pd.DataFrame.from_dict(run_data, orient='columns')\n",
    "        clear_output(wait=True)\n",
    "        display(df2)\n",
    "            \n",
    "#             m.track_loss(G_adv_loss=losses['beta_kl-divergence'], G_mse_loss=losses[''], D_real_loss=total_D_real, D_fake_loss=total_D_fake, D_real_count=real_count, D_fake_count=fake_count)\n",
    "#         print(epoch, \"total_Gloss:\",total_Gloss, \"total_Dloss:\",total_Dloss, \"mse:\",total_mse_loss, \"adv: \", total_adv_loss)           \n",
    "#         m.end_epoch()\n",
    "        torch.save(model, 'trained_models/mnist_ae_zdim_2.model'.format(run.lr,run.beta, run.z_dim))\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "skilled-closure",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = train_set[1].unsqueeze(dim=1)\n",
    "model = model.to('cpu')\n",
    "model.eval()\n",
    "\n",
    "out = model(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adjusted-treat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1131c97860>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(out.detach().squeeze().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hired-spain",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "popular-smile",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0824, 0.2471, 0.7176,\n",
       "          0.8863, 0.3765, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5686, 0.9490, 0.9961,\n",
       "          0.9961, 0.9765, 0.8706, 0.7608, 0.4941, 0.2000, 0.0431, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5647, 0.9765,\n",
       "          0.3843, 0.4706, 0.6510, 0.9961, 0.9961, 0.9961, 0.5843, 0.0431,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5647, 0.9412,\n",
       "          0.0000, 0.0000, 0.0039, 0.0157, 0.2196, 0.8627, 0.9961, 0.4863,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8902, 0.7608,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1255, 0.8314, 0.6667,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2353, 0.9843, 0.5608,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6431, 0.9608,\n",
       "          0.1765, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3255, 0.9961, 0.5608,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1647, 0.7176, 0.9686,\n",
       "          0.1922, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6353, 0.9961, 0.5961,\n",
       "          0.0784, 0.2863, 0.4706, 0.8314, 0.8314, 0.9608, 0.9765, 0.6549,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.2706, 0.7961, 0.9961, 0.9961,\n",
       "          0.9961, 0.9961, 0.9961, 0.9059, 0.6745, 0.5255, 0.2235, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0431, 0.2275, 0.5647, 0.9333, 0.9882, 0.9961, 0.9608, 0.8078,\n",
       "          0.5490, 0.4353, 0.1333, 0.0392, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
       "          0.7059, 0.9922, 0.9412, 0.5765, 0.4549, 0.9961, 0.5020, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1961, 0.7961,\n",
       "          0.9294, 0.3451, 0.0000, 0.0000, 0.0784, 0.9961, 0.4353, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6980, 0.9373,\n",
       "          0.2118, 0.0000, 0.0000, 0.0000, 0.0784, 0.9961, 0.4353, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3569, 0.9686, 0.4745,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0784, 0.9961, 0.4353, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6235, 0.8863, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.1843, 0.9961, 0.4353, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6235, 0.6824, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.5098, 1.0000, 0.0902, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6235, 0.6549, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0078, 0.8353, 0.5961, 0.0157, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6235, 0.9569, 0.2706,\n",
       "          0.0000, 0.0000, 0.0941, 0.7020, 0.9765, 0.2235, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1647, 0.8824, 0.8235,\n",
       "          0.5098, 0.5451, 0.9255, 0.9686, 0.3725, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3098, 0.8980,\n",
       "          0.9961, 0.9608, 0.6196, 0.2078, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "authorized-practice",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/sagar/Projects/flow/glow-pytorch/dataset.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.dataset = torch.tensor(self.dataset, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "from dataset import MNISTDataset\n",
    "\n",
    "import torch\n",
    "import os\n",
    "\n",
    "train_set = MNISTDataset('data/MNIST/processed', normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cardiac-watts",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "handmade-psychology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f057a527b70>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_set[0].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "elementary-denial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.3860, -0.1951,\n",
       "          -0.1951, -0.1951,  1.1795,  1.3068,  1.8032, -0.0933,  1.6887,\n",
       "           2.8215,  2.7197,  1.1923, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.0424,  0.0340,  0.7722,  1.5359,  1.7396,  2.7960,\n",
       "           2.7960,  2.7960,  2.7960,  2.7960,  2.4396,  1.7650,  2.7960,\n",
       "           2.6560,  2.0578,  0.3904, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           0.1995,  2.6051,  2.7960,  2.7960,  2.7960,  2.7960,  2.7960,\n",
       "           2.7960,  2.7960,  2.7960,  2.7706,  0.7595,  0.6195,  0.6195,\n",
       "           0.2886,  0.0722, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.1951,  2.3633,  2.7960,  2.7960,  2.7960,  2.7960,  2.7960,\n",
       "           2.0960,  1.8923,  2.7197,  2.6433, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242,  0.5940,  1.5614,  0.9377,  2.7960,  2.7960,  2.1851,\n",
       "          -0.2842, -0.4242,  0.1231,  1.5359, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.2460, -0.4115,  1.5359,  2.7960,  0.7213,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242,  1.3450,  2.7960,  1.9942,\n",
       "          -0.3988, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.2842,  1.9942,  2.7960,\n",
       "           0.4668, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.0213,  2.6433,\n",
       "           2.4396,  1.6123,  0.9504, -0.4115, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.6068,\n",
       "           2.6306,  2.7960,  2.7960,  1.0904, -0.1060, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           0.1486,  1.9432,  2.7960,  2.7960,  1.4850, -0.0806, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.2206,  0.7595,  2.7833,  2.7960,  1.9560, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242,  2.7451,  2.7960,  2.7451,  0.3904,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           0.1613,  1.2305,  1.9051,  2.7960,  2.7960,  2.2105, -0.3988,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.0722,  1.4596,\n",
       "           2.4906,  2.7960,  2.7960,  2.7960,  2.7578,  1.8923, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.1187,  1.0268,  2.3887,  2.7960,\n",
       "           2.7960,  2.7960,  2.7960,  2.1342,  0.5686, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.1315,  0.4159,  2.2869,  2.7960,  2.7960,  2.7960,\n",
       "           2.7960,  2.0960,  0.6068, -0.3988, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.1951,\n",
       "           1.7523,  2.3633,  2.7960,  2.7960,  2.7960,  2.7960,  2.0578,\n",
       "           0.5940, -0.3097, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242,  0.2758,  1.7650,  2.4524,\n",
       "           2.7960,  2.7960,  2.7960,  2.7960,  2.6815,  1.2686, -0.2842,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242,  1.3068,  2.7960,  2.7960,\n",
       "           2.7960,  2.2742,  1.2941,  1.2559, -0.2206, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "searching-gallery",
   "metadata": {},
   "outputs": [],
   "source": [
    "ld = torch.utils.data.DataLoader(train_set, transform=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "progressive-ukraine",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import MNISTDataset\n",
    "\n",
    "import torch\n",
    "import os\n",
    "data = torch.load(os.path.join('data/MNIST/processed', 'training.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "alleged-impossible",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/sagar/Projects/learn/compressai/venv/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "a, _ = data\n",
    "a = torch.tensor(a, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-theorem",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "satisfied-tribune",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,_ = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "south-ghana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3081)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a/255.0).std()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
